{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OBJECTIVE :- Model Evaluation and Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "mbMr1v7nf85y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Breast Cancer Classification using Machine Learning\n",
        "\n",
        "This notebook trains and evaluates multiple machine learning models on the [Breast Cancer Wisconsin dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) to classify tumors as **malignant or benign**. It includes:\n",
        "\n",
        "* Logistic Regression\n",
        "* Random Forest\n",
        "* Support Vector Machine (SVM)\n",
        "\n",
        "Each model undergoes **hyperparameter tuning** using `GridSearchCV` or `RandomizedSearchCV` and is evaluated using metrics like **accuracy**, **precision**, **recall**, and **F1-score**.\n"
      ],
      "metadata": {
        "id": "HViSmjFzfSco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Import necessary libraries"
      ],
      "metadata": {
        "id": "MXs1HlzCehV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
      ],
      "metadata": {
        "id": "vfN4YP8ZbfKT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load dataset"
      ],
      "metadata": {
        "id": "BMYeH3xBerai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "Vl9wGi6pbhMA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train/test split"
      ],
      "metadata": {
        "id": "1xeh-wHVexb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "31m3BPvLbjGq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preprocessing + Pipelines"
      ],
      "metadata": {
        "id": "3MUBnxahe2TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_lr = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=10000))])\n",
        "pipe_rf = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state=42))])\n",
        "pipe_svc = Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42))])\n"
      ],
      "metadata": {
        "id": "LzDhO_kSbl87"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Define hyperparameter grids"
      ],
      "metadata": {
        "id": "yenQu0kpe5QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_grid_lr = {'clf__C': [0.01, 0.1, 1, 10, 100], 'clf__penalty': ['l2']}\n",
        "param_dist_rf = {'clf__n_estimators': [50, 100],'clf__max_depth': [None, 5, 10],'clf__max_features': ['sqrt', 'log2']}\n",
        "param_grid_svc = {'clf__C': [0.1, 1, 10], 'clf__kernel': ['linear', 'rbf'], 'clf__gamma': ['scale', 'auto']}\n"
      ],
      "metadata": {
        "id": "4SNr7nwrbolU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. GridSearchCV & RandomizedSearchCV setups"
      ],
      "metadata": {
        "id": "3aIt7MS2e9BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_rf = RandomizedSearchCV(pipe_rf,param_distributions=param_dist_rf, cv=5,scoring='f1',n_iter=10,random_state=42,n_jobs=-1)\n",
        "grid_svc = GridSearchCV(pipe_svc, param_grid_svc, cv=5, scoring='f1', n_jobs=-1)\n"
      ],
      "metadata": {
        "id": "S7Dul3xTbrqO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Train models"
      ],
      "metadata": {
        "id": "3Nsi5qhDe_rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for name, model in [('Logistic Regression', grid_lr),\n",
        "                    ('Random Forest', grid_rf),\n",
        "                    ('SVM', grid_svc)]:\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"  Best params: {model.best_params_}\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"  Metrics on test set:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfrM63F4bvL4",
        "outputId": "17650da1-aad9-47c2-d319-705da2e5cff7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "  Best params: {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
            "  Metrics on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9756    0.9524    0.9639        42\n",
            "           1     0.9726    0.9861    0.9793        72\n",
            "\n",
            "    accuracy                         0.9737       114\n",
            "   macro avg     0.9741    0.9692    0.9716       114\n",
            "weighted avg     0.9737    0.9737    0.9736       114\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "  Best params: {'clf__n_estimators': 100, 'clf__max_features': 'log2', 'clf__max_depth': 10}\n",
            "  Metrics on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9512    0.9286    0.9398        42\n",
            "           1     0.9589    0.9722    0.9655        72\n",
            "\n",
            "    accuracy                         0.9561       114\n",
            "   macro avg     0.9551    0.9504    0.9526       114\n",
            "weighted avg     0.9561    0.9561    0.9560       114\n",
            "\n",
            "\n",
            "Training SVM...\n",
            "  Best params: {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
            "  Metrics on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9762    0.9762    0.9762        42\n",
            "           1     0.9861    0.9861    0.9861        72\n",
            "\n",
            "    accuracy                         0.9825       114\n",
            "   macro avg     0.9812    0.9812    0.9812       114\n",
            "weighted avg     0.9825    0.9825    0.9825       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Compare results"
      ],
      "metadata": {
        "id": "EpadG_Xpeay4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9UuIrxfZJJs",
        "outputId": "14ed128b-1231-43a1-f3da-fc2fa20a8069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of performance metrics:\n",
            "                     accuracy  precision    recall  f1_score\n",
            "SVM                  0.982456   0.986111  0.986111  0.986111\n",
            "Logistic Regression  0.973684   0.972603  0.986111  0.979310\n",
            "Random Forest        0.956140   0.958904  0.972222  0.965517\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "for name, model in [('Logistic Regression', grid_lr),\n",
        "                    ('Random Forest', grid_rf),\n",
        "                    ('SVM', grid_svc)]:\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1_score': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "df_results = pd.DataFrame(results).T\n",
        "print(\"\\nSummary of performance metrics:\")\n",
        "print(df_results.sort_values(by='f1_score', ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Performing Model: SVM\n",
        "Highest F1-score, which balances precision and recall.\n",
        "\n",
        "Also has the best precision and recall independently.\n",
        "\n",
        "No overfitting signs great performance on test set."
      ],
      "metadata": {
        "id": "vzugidOwfLD1"
      }
    }
  ]
}